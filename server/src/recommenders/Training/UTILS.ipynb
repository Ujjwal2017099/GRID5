{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2in_MRaEulgS",
        "outputId": "44c23229-09f2-47fa-a47a-f6e1780ba6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd, numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "metadata": {
        "id": "PXF4B4emCAB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PRE-PROCESSING"
      ],
      "metadata": {
        "id": "2theEXDOn5d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_count_of_user(df):\n",
        "  counts = df.user_id.value_counts()\n",
        "  return counts\n",
        "\n",
        "def generate_most_rated_users_df(df, counts, count):\n",
        "  most_rated_users = df[df.user_id.isin(counts[counts >= count].index)]\n",
        "  print('Number of users who have rated', count, 'or more items =', len(most_rated_users))\n",
        "  print('Number of unique users in the final data = ', most_rated_users['user_id'].nunique())\n",
        "  print('Number of unique products in the final data = ', most_rated_users['item_id'].nunique())\n",
        "  return most_rated_users\n",
        "\n",
        "def generate_pivot(df, index, columns, values, fillna=True):\n",
        "  df_pivot = df.pivot_table(index=index, columns=columns, values=values)\n",
        "  if fillna:\n",
        "    df_pivot = df_pivot.fillna(0)\n",
        "  return df_pivot\n",
        "\n",
        "def generate_SVD_pivot(pivot_df):\n",
        "  U, sigma, Vt = np.linalg.svd(pivot_df, full_matrices=False)\n",
        "  sigma = np.diag(sigma)\n",
        "\n",
        "  # predicted ratings\n",
        "  predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "  predicted_ratings.shape\n",
        "\n",
        "  # Convert predicted ratings to dataframe\n",
        "  preds_df = pd.DataFrame(predicted_ratings, columns = pivot_df.columns)\n",
        "  return preds_df\n",
        "\n",
        "def generate_rmse_df(pivot_df, preds_df):\n",
        "  rmse_df = pd.concat([pivot_df.mean(), preds_df.mean()], axis=1)\n",
        "  rmse_df.columns = ['Avg_actual_ratings', 'Avg_predicted_ratings']\n",
        "  # print(rmse_df.shape)\n",
        "  # rmse_df.head()\n",
        "  return rmse_df\n",
        "\n",
        "def rmse_error(rmse_df):\n",
        "  RMSE = round((((rmse_df.Avg_actual_ratings - rmse_df.Avg_predicted_ratings) ** 2).mean() ** 0.5), 5)\n",
        "  print('\\nRMSE SVD Model = {} \\n'.format(RMSE))\n",
        "  return RMSE"
      ],
      "metadata": {
        "id": "_0xZOM1ZjzFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ITEM-ITEM SIMILARITY"
      ],
      "metadata": {
        "id": "MhsyHC5JnotN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "import sklearn\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "\n",
        "def SVD_item_item_similarity(pivot_df, n_components=12):\n",
        "  # pivot_df = generate_pivot(df, index, columns, values)\n",
        "  X = pivot_df.values.T\n",
        "\n",
        "  SVD = TruncatedSVD(n_components=n_components, random_state=17)\n",
        "  matrix = SVD.fit_transform(X)\n",
        "  # matrix.shape\n",
        "\n",
        "  # Correlation matrix between ITEMS\n",
        "  corr = np.corrcoef(matrix)\n",
        "  # corr.shape\n",
        "\n",
        "  return corr\n",
        "\n",
        "def recommend_items_SVD(corr, pivot_df_columns_list, item_id):\n",
        "  index = pivot_df_columns_list.index(item_id)\n",
        "  corr_list = corr[index]\n",
        "\n",
        "  # Top 5 items\n",
        "  ind = np.argpartition(corr_list, -6)[-6:]\n",
        "  ind = ind[np.argsort(corr_list[ind])]\n",
        "  ind = ind[ :-1]\n",
        "\n",
        "  res = []\n",
        "  for i in ind:\n",
        "    res.append(pivot_df_columns_list[i])\n",
        "\n",
        "  print(res)\n",
        "  return res\n",
        "\n",
        "\n",
        "\n",
        "def knn_item_item_similarity(df, index='item_id', columns='user_id', values='rating'):\n",
        "  pivot_df = generate_pivot(df, index, columns, values)\n",
        "  pivot_df_csr_matrix = csr_matrix(pivot_df.values)\n",
        "\n",
        "  model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')\n",
        "  model_knn.fit(pivot_df_csr_matrix)\n",
        "\n",
        "  return pivot_df, model_knn\n",
        "\n",
        "\n",
        "def recommend_items_knn(model, pivot_df, isbn_id):\n",
        "  # query_index = np.random.choice(pivot_df.shape[0])\n",
        "  isbn = list(pivot_df.index)\n",
        "  query_index = isbn.index(isbn_id)\n",
        "\n",
        "  distances, indices = model.kneighbors(pivot_df.iloc[query_index, :].values.reshape((1, -1)), n_neighbors = 6)\n",
        "\n",
        "  for i in range(0, len(distances.flatten())):\n",
        "      if i == 0:\n",
        "          print('Recommendations for {0}:\\n'.format(pivot_df.index[query_index]))\n",
        "      else:\n",
        "          print('{0}: {1}, with distance of {2}:'.format(i, pivot_df.index[indices.flatten()[i]], distances.flatten()[i]))\n"
      ],
      "metadata": {
        "id": "1SyN9DDPmXce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USER-USER SIMILARITY"
      ],
      "metadata": {
        "id": "bf03a4kEcDSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "def normalize_pivot_matrix(df_pivot):\n",
        "  df_pivot_norm = df_pivot.subtract(df_pivot.mean(axis=1), axis='rows')\n",
        "  return df_pivot_norm\n",
        "\n",
        "def similarity_matrix_Pearson(df_pivot_norm):\n",
        "  user_similarity = df_pivot_norm.T.corr()\n",
        "  return user_similarity\n",
        "\n",
        "def similarity_matrix_Cosine(df_pivot_norm):\n",
        "  user_similarity = cosine_similarity(df_pivot_norm.fillna(0))\n",
        "  print(type(user_similarity))\n",
        "  return user_similarity\n",
        "\n",
        "def exclude_given_user(user_id, user_similarity):\n",
        "  user_similarity = user_similarity.drop(index=user_id)\n",
        "  return user_similarity\n",
        "\n",
        "def get_similar_users(user_id, threshold, user_similarity, n=5):\n",
        "  # n = no. of users\n",
        "  similar_users = user_similarity[user_similarity[user_id] > threshold][user_id].sort_values(ascending=False)[:n]\n",
        "  print(similar_users)\n",
        "  return similar_users\n",
        "\n",
        "def get_interacted_items(user_id, df_pivot_norm):\n",
        "  # Items that the target user has interacted\n",
        "  interacted_df = df_pivot_norm[df_pivot_norm.index == user_id].dropna(axis=1, how='all')\n",
        "  return interacted_df\n",
        "\n",
        "def get_similar_users_items(df_pivot_norm, similar_users, interacted_df):\n",
        "  # remove not interacted items in similar users\n",
        "  similar_user_items = df_pivot_norm[df_pivot_norm.index.isin(similar_users.index)].dropna(axis=1, how='all')\n",
        "\n",
        "  # remove target user interacted items\n",
        "  similar_user_items = similar_user_items.drop(interacted_df.columns, axis=1, errors='ignore')\n",
        "\n",
        "  return similar_user_items\n",
        "\n",
        "def recommend_items_User_Based(similar_users, similar_user_items, n = 5):\n",
        "  # A dictionary to store item scores\n",
        "  item_score = {}\n",
        "\n",
        "  # Loop through items\n",
        "  for i in similar_user_items.columns:\n",
        "    # Get the ratings for movie i\n",
        "    item_rating = similar_user_items[i]\n",
        "    # Create a variable to store the score\n",
        "    total = 0\n",
        "    # Create a variable to store the number of scores\n",
        "    count = 0\n",
        "    # Loop through similar users\n",
        "    for u in similar_users.index:\n",
        "      # If the movie has rating\n",
        "      if pd.isna(item_rating[u]) == False:\n",
        "        # Score is the sum of user similarity score multiply by the movie rating\n",
        "        score = similar_users[u] * item_rating[u]\n",
        "        # Add the score to the total score for the movie so far\n",
        "        total += score\n",
        "        # Add 1 to the count\n",
        "        count +=1\n",
        "    # Get the average score for the item\n",
        "    item_score[i] = total / count\n",
        "\n",
        "  # Convert dictionary to pandas dataframe\n",
        "  item_score = pd.DataFrame(item_score.items(), columns=['movie', 'movie_score'])\n",
        "\n",
        "  # Sort the movies by score\n",
        "  ranked_item_score = item_score.sort_values(by='movie_score', ascending=False)\n",
        "\n",
        "  # Select top n movies\n",
        "  print(ranked_item_score.head(n))\n",
        "  return ranked_item_score.iloc[ :n, : ]\n"
      ],
      "metadata": {
        "id": "_cHGZaKYcG-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhEsNcaBdZJ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}